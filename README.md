# ec-ingredion-2

> Este projeto faz parte do curso de **InteligÃªncia Artificial** oferecido pela [FIAP](https://github.com/fiap) - Online 2024. Este repositÃ³rio reÃºne os materiais relacionados ao **Enterprise Challenge - Ingredion**, correspondendo Ã  **Sprint 2** do desafio.

- Video de ApresentaÃ§Ã£o: [Youtube]()
- Notebook para CorreÃ§Ã£o: [Jupyter Notebook](./src/ml.ipynb)

## DescriÃ§Ã£o

Este projeto desenvolve um modelo de aprendizado de mÃ¡quina para previsÃ£o de produtividade agrÃ­cola na regiÃ£o de ManhuaÃ§u (MG), substituindo mÃ©todos tradicionais de anÃ¡lise baseados em estimativas manuais e dados desconectados. Ao integrar imagens de satÃ©lite (Ã­ndice de vegetaÃ§Ã£o NDVI) e dados histÃ³ricos de produÃ§Ã£o, o modelo identifica padrÃµes sazonais e relaÃ§Ãµes entre saÃºde vegetal e produtividade, gerando previsÃµes precisas para auxiliar na tomada de decisÃµes. A soluÃ§Ã£o melhora a eficiÃªncia no planejamento agrÃ­cola, reduz perdas por fatores ambientais e otimiza a alocaÃ§Ã£o de recursos, sendo adaptÃ¡vel a diferentes culturas e escalÃ¡vel para outras regiÃµes.

## Estrutura de Arquivos

```txt
.
â”œâ”€â”€ data - Arquivos de entrada e saÃ­da usados no processo
â”‚   â”œâ”€â”€ PROCESSED
â”‚   â”‚   â”œâ”€â”€ manhuacu.csv
â”‚   â”‚   â””â”€â”€ ndvi.csv
â”‚   â”œâ”€â”€ GOOGLE_EARTH_ENGINE
â”‚   â”‚   â””â”€â”€ ndvi_manhuacu.csv - SÃ©rie NDVI (2000â€“2025): Google Earth Engine
â”‚   â””â”€â”€ SIDRA
â”‚       â””â”€â”€ tabela1613.xlsx - Dados de produÃ§Ã£o (1974â€“2023): IBGE/Tabela 1613
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ lstm.pth - Pesos do modelo LSTM
â”‚   â””â”€â”€ mlp.pth - Pesos do modelo MLP
â”œâ”€â”€ README.md - Este README
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ extract-ndvi-manhuacu.ipynb - Jupyter Notebook para extraÃ§Ã£o de dados NDVI de ManhuaÃ§u, MG
â”‚   â””â”€â”€ prepare-data.ipynb - Jupyter Notebook para preparaÃ§Ã£o de dados
â”œâ”€â”€ src
â”‚   â””â”€â”€ eda.ipynb - Notebook de AnÃ¡lise ExploratÃ³ria e EstatÃ­sticas Resultantes 
â”‚   â””â”€â”€ ml.ipynb - Notebook de ImplementaÃ§Ã£o dos Modelos de IA
â””â”€â”€ TODO.md - GestÃ£o do projeto
```

## DocumentaÃ§Ã£o

### PreparaÃ§Ã£o do Ambiente

#### Instalar o Python  

1. Baixe e instale a versÃ£o mais recente do Python (recomendado 3.7 ou superior) no [site oficial do Python](https://www.python.org/).  
2. Durante a instalaÃ§Ã£o, certifique-se de marcar a opÃ§Ã£o **"Add Python to PATH"**.  
3. Verifique as versÃµes do Python e do `pip`  
   Certifique-se de que o Python e o `pip` foram instalados corretamente executando:  
    ```bash
    python --version
    pip --version
    ```

#### Criar um Ambiente Virtual (Opcional, mas Recomendado)  

Usar um ambiente virtual isola as dependÃªncias do projeto.

1. Abra um terminal ou prompt de comando.  
2. Navegue atÃ© a pasta do projeto.  
3. Execute o seguinte comando para criar um ambiente virtual:  
   ```bash
   python -m venv venv
   ```  
4. Ative o ambiente virtual:  
   - No Windows:  
     ```bash
     venv\Scripts\activate
     ```  
   - No macOS/Linux:  
     ```bash
     source venv/bin/activate
     ```

#### Instalar as Bibliotecas NecessÃ¡rias

1. Instale o `pip` e o `setuptools` (se ainda nÃ£o estiverem instalados)  
   Atualize o `pip` e o `setuptools` para a versÃ£o mais recente:  
    ```bash
    pip install --upgrade pip setuptools
    ```  
2. Instale as Bibliotecas  
   Use o `pip` para instalar as bibliotecas necessÃ¡rias. Execute o comando:  
    ```bash
    pip install -r requirements.txt
    ```
   Mais detalhes sobre instalaÃ§Ã£o do PyTorch: https://pytorch.org/get-started/locally/

### Prints da AnÃ¡lise ExploratÃ³ria e EstatÃ­sticas Resultantes

[png1] [png2]

### Processo de PreparaÃ§Ã£o dos Dados

- Link para cÃ³digo e documentaÃ§Ã£o: [Jupyter Notebook](./scripts/prepare-data.ipynb)

### Funcionamento do CÃ³digo

#### Modelagem e Algoritmos

#### Abordagens Implementadas

Foram desenvolvidas e comparadas duas arquiteturas de redes neurais profundas, cada uma com caracterÃ­sticas especÃ­ficas para o problema de previsÃ£o de produtividade agrÃ­cola:

MLP (Multilayer Perceptron)	Rede neural densa para capturar padrÃµes nÃ£o lineares.	- Camadas ocultas: 32 â†’ 16 neurÃ´nios
 - FunÃ§Ã£o de ativaÃ§Ã£o: ReLU + Tanh amplificada
 - Janela temporal: 5 observaÃ§Ãµes

LSTM (Long Short-Term Memory)	Rede recorrente para dependÃªncias temporais de longo prazo.	- Camadas LSTM: 2
 - NeurÃ´nios ocultos: 32
 - Janela temporal: 20 observaÃ§Ãµes

CritÃ©rio de Escolha:
 - MLP: Simplicidade e eficiÃªncia para padrÃµes anuais.
 - LSTM: Capacidade de memorizar variaÃ§Ãµes sazonais complexas.

### Justificativa da Escolha das VariÃ¡veis

### Justificativa do Modelo e sua LÃ³gica Preditiva

### Justificativa TÃ©cnica com MÃ©tricas e GrÃ¡ficos Ilustrando os Resultados

## Equipe

### Membros

- Amandha Nery (RM560030) 
- Bruno Conterato (RM561048)
- Gustavo Castro (RM560831)
- Kild Fernandes (RM560615)
- Luis Emidio (RM559976)

### Professores

- Tutor: Leonardo Ruiz Orabona
- Coordenador: AndrÃ© Godoi

## Tecnologias Utilizadas

| Categoria             | Ferramentas                  |
|------------------------|-------------------------------|
| Linguagem              | Python 3.9+                   |
| ManipulaÃ§Ã£o de Dados   | Pandas, NumPy                 |
| VisualizaÃ§Ã£o           | Matplotlib                    |
| Aprendizado Profundo   | PyTorch                       |
| PrÃ©-processamento      | Scikit-learn (StandardScaler) |
| Ambiente               | Jupyter Notebook, CUDA (GPU)  |

## Contato

Se tiver alguma dÃºvida, sinta-se Ã  vontade para entrar em contato. ğŸš€
